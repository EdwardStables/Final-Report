\section{Introduction}\label{section_introduction}
The field of mathematical optimisation faces a problem in that the vast majority of available software packages are designed in a manner that disallows easy modification or adaption of the software internals. This is due to these packages using compiled languages that do not lend themselves to easy modification, as well as being highly optimised for performance. While these are desirable characteristics for deployed software, or circumstances where a specified algorithm is required, it is problematic in an developmental setting where the ability to experiment with aspects of an algorithm is generally more desirable than the performance of the software. 

This project intends to tackle this issue by implementing a pair of optimisation software packages which are designed in such a way that experimentation and modification of algorithms is simple, but performance is still competitive with traditional software packages. The increasing popularity of the Julia programming language \cite{Bezanson2017Julia:Computing} has inspired this project as the software paradigm it offers is unique. Julia offers a familiar mathematical syntax, a code structure that is perfectly suited to the aim of the project, and better performance than the vast majority of its contemporaries \cite{JuliaMicrobenchmarks}.

To the best of our knowledge there are no equivalent optimisation software packages that prioritise this algorithmic flexibility, let alone ones that also maintain the majority of the performance of their highly optimised counterparts. 

%\subsection{Project Objectives}
%In this project we have utilised Julia to develop a pair of native optimisation packages that are specifically designed to allow for extension and modification as needed. Algorithmic contributions to these packages is possible without requiring a detailed knowledge of the software architecture and the language specific `tricks' needed for gaining high performance. These two packages respectively focus on the implementation of different classes of algorithms, and are structured to facilitate high performance in these specific circumstances.
%
%The specific requirements of each piece of software developed in the project are covered in Section \ref{sec:requirements}.
%
%\subsection{Julia}
%Julia has recently begun gaining traction in the numerical programming community due to its combination of powerful syntax, performance, and utility. It is commonly compared to the languages MATLAB, Python, and C, combining aspects of all three to create a very interesting new platform for programming in this space.
%
%MATLAB is first and foremost designed as a numerical programming language, limiting its utility in general purpose use-cases (as well as being limited by licensing). Python is famous for its speed of development and expressive syntax, but has slow performance and few restrictions on types, leading to hidden bugs. Finally, C remains a very high performance language, but struggles to provide an environment that allows for rapid implementation and extension of algorithms created with it. Julia takes each of these problems and provides a language with an expressive syntax focused on mathematical programming, a very powerful typing system, and performance that can be near that of native C code in many circumstances. This flexibility has led to Julia being described as a solution to the `two language problem' by its authors, allowing both algorithm design and release software to be within the same code-base \cite{TheBottomLine2018Julia:Problem}.
%
%More detail on the aspects of Julia that make it suited to this project are given in Section \ref{sec:background}.

%\subsection{Packages and Algorithms}
The two packages being developed in this project each focus on a different subset of optimisation algorithms. The first focuses on row action methods, and the second on direct-search methods. These are named \ac{RAM} and \ac{DS} respectively (these names follow the Julia convention of appending `\textit{.jl}' to signify package names).

Row action methods are a class of algorithm that are characterised by only accessing a single row of a problem matrix at a time, and have shown good performance when applied to large and sparse problems \cite{ROW-ACTIONCENSORS}. One of the motivations of using these algorithms is the promise that they have shown when utilised in a distributed computing environment \cite{Liu2014AnAlgorithm}. It is not believed that there are any alternative software packages that focus solely on these kinds of methods.

Direct search methods are a broad class of derivative free optimisation algorithms, with many different algorithms fitting within the classification \cite{2008DirectionalMethods}. The subset of direct search algorithms being focused on in this project is the \ac{MADS} family of algorithms \cite{Audet2007MeshOptimization}. \ac{MADS} requires no analytical knowledge about the objective function or constraints of a problem. It has been shown to be effective when the objective function is very expensive to calculate (therefore a minimum number of evaluations is desirable), as well as for non-smooth functions (making the application of solvers that have a requirement for derivative information or smoothness ineffective).

The software and algorithms developed in this project will be extensively tested to ensure that they are free of error, and benchmarked to demonstrate that they offer very similar performance to algorithms that do not offer the same degree of flexibility.
