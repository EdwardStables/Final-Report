\section{Project Specification}
After the commencement of the project, a meeting was held where the exact focus of the project was discussed, with the initial aim being to select a set of solvers to implement in Julia. It was important to choose solvers that were representative of a broad range of algorithm types, but also to not replicate any work that had already been done to implement solvers in native Julia. 

In order to showcase derivative-free, first-order, and second-order solvers the decision was made to implement the MADS \cite{Audet2007MeshOptimization}, OSQP \cite{Stellato2017OSQP:Programs}, and PIPS-NLP \cite{ChiangStructuredPIPS-NLP} algorithms respectively. In addition, an implementation of Hildreth's Algorithm \cite{HildrethAPROCEDURE} would be included to provide an implementation of the class of algorithms known as row-action methods. The specifics of these algorithms will be discussed further in Section \ref{sec_background}. 

During the implementation of Hildreth's algorithm it was remarked that the design of the package would be very easy to generalise to an entire category of solvers, with Julia's multiple dispatch paradigm allowing this to be added with very minimal changes. This feature of Julia, and the design patterns it enables, is discussed further in Section \ref{sub_julia}. As such we decided to transition the aim of the current sub-project to design a framework in which any row-action method (the class of method to which Hildreth's algorithm belongs) can easily be implemented. It was also discussed whether this idea could also be applied to the MADS algorithm sub-project, by implementing a framework for direct-search methods rather than just the MADS algorithm itself. 

At the time of writing, details of the OSQP and PIPS-NLP sub-projects have not been discussed in detail and it is not decided whether they will be designed as single solvers or frameworks for a broader class of optimisation algorithms, although it is likely that they will be more focused on the specific algorithms, with the ability to heavily customise specific aspects of the algorithms.

As previously remarked, the aim or the project is not to develop algorithms of a higher performance than existing solvers. However, well written Julia code is able to offer very high performance \cite{JuliaMicro-Benchmarks} with appropriate tuning \cite{PerformanceLanguage}. While we will prefer simple design and readable code over minor performance improvements, the design will attempt to achieve the highest performance reasonable.

Aside from the implementation of the algorithms/frameworks themselves, it is an important requirement to ensure compatibility with the existing Julia optimisation ecosystem. The vast majority of Julia optimisation code implements a low-level API called MathOptInterface (MOI) \cite{ManualMathOptInterface} which allows for abstracted use of high level problem description packages without needing to know the APIs of individual solvers. This allows us to apply the same problem to two optimisation solvers and compare the results without needing to formulate the problem in two different ways for each of the solvers. 

As this is a project that will be released on an open-source license and will continue to have contributions to it in the future, it is also a requirement to ensure good software development practices are maintained. Employing good practices will ensure that the code is maintainable by a wide group of people, and has a level of ensured reliability. The two key aspects of this are documentation, and testing. The specifics of which will be discussed in Section \ref{sec_implementation}.
